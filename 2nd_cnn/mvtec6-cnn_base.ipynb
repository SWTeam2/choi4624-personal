{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cKUpzmsX-qcM",
        "outputId": "a14aabc9-6b85-49d8-ac96-c57d07766a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/colab/mvtec_anomaly_detection\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcGsc7XD_Vvq",
        "outputId": "4b6905f9-2c55-4852-c0f9-5fce3b9cd327"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/colab\n"
          ]
        }
      ],
      "source": [
        "%cd /content/drive/MyDrive/colab/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbKrFmaE9wZP",
        "outputId": "7b7bfa27-68cf-44d8-e4ab-c602ee3a0861"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/colab\n",
            "Found 267 images belonging to 1 classes.\n",
            "Found 167 images belonging to 8 classes.\n",
            "Found 167 images belonging to 8 classes.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "print(os.getcwd())\n",
        "os.getcwd()\n",
        "\n",
        "# Define directories for your dataset\n",
        "base_dir = './mvtec_anomaly_detection/'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'pill', 'train')\n",
        "validation_dir = os.path.join(base_dir, 'pill', 'test')\n",
        "test_dir = os.path.join(base_dir, 'pill', 'test')\n",
        "\n",
        "\n",
        "# Define image preprocessing and augmentation options\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalize pixel values between 0 and 1\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)  # Only rescale for test set\n",
        "\n",
        "# Generate batches of augmented training data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(150, 150),  # Resize images to a fixed size\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'  # For classification tasks\n",
        ")\n",
        "\n",
        "# Generate batches of validation data\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n",
        "\n",
        "# Generate batches of test data\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=(150, 150),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "ROFD2IyvEetW",
        "outputId": "feff042a-eee6-4329-895a-32330b29d081"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-03c3ffcbf097>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresnet50\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpreprocess_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras.applications.resnet50'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BXRIXE9qCKCz",
        "outputId": "268f3e43-c350-4e3b-ff44-209850e1def8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<keras.preprocessing.image.DirectoryIterator object at 0x79e542f23bb0>\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "id": "-15xFF9s_g8g",
        "outputId": "d01dd4c9-0d05-43f3-919a-99c85e08cfdd"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-3e66ba0dcd90>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mpooling\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'kwargs' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "tf.keras.applications.ResNet50(\n",
        "    include_top=True,\n",
        "    weights=\"imagenet\",\n",
        "    input_tensor=None,\n",
        "    input_shape=None,\n",
        "    pooling=None,\n",
        "    classes=8,\n",
        "    **kwargs\n",
        ")\n",
        "\n",
        "model = ResNet50(weights='imagenet')\n",
        "\n",
        "# Create a sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add convolutional layers\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 3)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "\n",
        "# Flatten the feature maps\n",
        "model.add(Flatten())\n",
        "\n",
        "# Add fully connected layers\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(2, activation='softmax'))  # Assuming 2 classes (good and defect)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=len(validation_generator)\n",
        ")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "wJIWwAaZEBIi"
      },
      "outputs": [],
      "source": [
        "def load_images(dir):\n",
        "  \"\"\"Loads all images in a directory.\"\"\"\n",
        "  images = []\n",
        "  for filename in os.listdir(dir):\n",
        "    path = os.path.join(dir, filename)\n",
        "    images.append(path)\n",
        "  return images\n",
        "\n",
        "img_path = load_images(train_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7-beuPRD2Fw",
        "outputId": "bc672cdc-2714-4993-f84a-a80658ade2c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "9/9 [==============================] - 17s 2s/step - loss: 41245491200.0000 - accuracy: 0.1199 - val_loss: 4635769856.0000 - val_accuracy: 0.1437\n",
            "Epoch 2/20\n",
            "9/9 [==============================] - 15s 2s/step - loss: 41643536384.0000 - accuracy: 0.0000e+00 - val_loss: 4743202304.0000 - val_accuracy: 0.0539\n",
            "Epoch 3/20\n",
            "9/9 [==============================] - 20s 2s/step - loss: 44334411776.0000 - accuracy: 0.1610 - val_loss: 5175751680.0000 - val_accuracy: 0.1257\n",
            "Epoch 4/20\n",
            "9/9 [==============================] - 15s 2s/step - loss: 47982247936.0000 - accuracy: 0.2397 - val_loss: 6002683392.0000 - val_accuracy: 0.1138\n",
            "Epoch 5/20\n",
            "9/9 [==============================] - 15s 2s/step - loss: 54250090496.0000 - accuracy: 0.0000e+00 - val_loss: 6354566144.0000 - val_accuracy: 0.1437\n",
            "Epoch 6/20\n",
            "9/9 [==============================] - 15s 2s/step - loss: 58322538496.0000 - accuracy: 0.1610 - val_loss: 6992474624.0000 - val_accuracy: 0.1557\n",
            "Epoch 7/20\n",
            "9/9 [==============================] - 15s 2s/step - loss: 66296102912.0000 - accuracy: 0.2397 - val_loss: 8333232640.0000 - val_accuracy: 0.1437\n",
            "Epoch 8/20\n",
            "9/9 [==============================] - 15s 2s/step - loss: 72777580544.0000 - accuracy: 0.0000e+00 - val_loss: 8866929664.0000 - val_accuracy: 0.1138\n",
            "Epoch 9/20\n",
            "9/9 [==============================] - 15s 2s/step - loss: 71693713408.0000 - accuracy: 0.2397 - val_loss: 8689728512.0000 - val_accuracy: 0.1437\n",
            "Epoch 10/20\n",
            "9/9 [==============================] - 15s 2s/step - loss: 79761481728.0000 - accuracy: 0.1199 - val_loss: 8933327872.0000 - val_accuracy: 0.1497\n",
            "Epoch 11/20\n",
            "9/9 [==============================] - 15s 2s/step - loss: 80549502976.0000 - accuracy: 0.1199 - val_loss: 8969754624.0000 - val_accuracy: 0.1437\n",
            "Epoch 12/20\n",
            "9/9 [==============================] - 15s 2s/step - loss: 86114844672.0000 - accuracy: 0.2397 - val_loss: 10996793344.0000 - val_accuracy: 0.1557\n",
            "Epoch 13/20\n",
            "9/9 [==============================] - 15s 2s/step - loss: 90812456960.0000 - accuracy: 0.0000e+00 - val_loss: 11797346304.0000 - val_accuracy: 0.1497\n",
            "Epoch 14/20\n",
            "9/9 [==============================] - 15s 2s/step - loss: 93791313920.0000 - accuracy: 0.2397 - val_loss: 10306733056.0000 - val_accuracy: 0.1437\n",
            "Epoch 15/20\n",
            "9/9 [==============================] - 15s 2s/step - loss: 78944337920.0000 - accuracy: 0.1199 - val_loss: 10068012032.0000 - val_accuracy: 0.1557\n",
            "Epoch 16/20\n",
            "9/9 [==============================] - 15s 2s/step - loss: 85686607872.0000 - accuracy: 0.2397 - val_loss: 11911929856.0000 - val_accuracy: 0.1138\n",
            "Epoch 17/20\n",
            "9/9 [==============================] - 15s 2s/step - loss: 64439443456.0000 - accuracy: 0.1199 - val_loss: 7003056128.0000 - val_accuracy: 0.1557\n",
            "Epoch 18/20\n",
            "9/9 [==============================] - 15s 2s/step - loss: 41878708224.0000 - accuracy: 0.1199 - val_loss: 5362637312.0000 - val_accuracy: 0.1557\n",
            "Epoch 19/20\n",
            "9/9 [==============================] - 15s 2s/step - loss: 62394286080.0000 - accuracy: 0.0412 - val_loss: 10939133952.0000 - val_accuracy: 0.1557\n",
            "Epoch 20/20\n",
            "9/9 [==============================] - 15s 2s/step - loss: 81569595392.0000 - accuracy: 0.1199 - val_loss: 13032003584.0000 - val_accuracy: 0.1497\n"
          ]
        }
      ],
      "source": [
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(train_generator),\n",
        "    epochs=20,\n",
        "    validation_data=validation_generator,\n",
        "    validation_steps=len(validation_generator)\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
